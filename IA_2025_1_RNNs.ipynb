{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "py1lu2h6rGke"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDmkr2egLEbf"
      },
      "source": [
        "# Parte 3: Generación de musica con Redenes Neuronales Recurrentes (RNNs)\n",
        "\n",
        "En esta parte del laboratorio, exploraremos la construcción de una red neuronal recurrente (RNN) para la generación de música. Entrenaremos un modelo para aprender los patrones en partituras sin procesar en [notación ABC](https://en.wikipedia.org/wiki/ABC_notation) y luego usaremos este modelo para generar música.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfFb9qNbMVvt"
      },
      "source": [
        "## 3.1 Importar dependencias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TDtATZpWMdCn"
      },
      "outputs": [],
      "source": [
        "# Import Tensorflow 2.0\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "\n",
        "# Download and import the MIT 6.S191 package\n",
        "!pip install mitdeeplearning\n",
        "import mitdeeplearning as mdl\n",
        "\n",
        "# Import all remaining packages\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import functools\n",
        "from IPython import display as ipythondisplay\n",
        "from tqdm import tqdm\n",
        "!apt-get install abcmidi timidity > /dev/null 2>&1\n",
        "\n",
        "# Check that we are using a GPU, if not switch runtimes\n",
        "#   using Runtime > Change Runtime Type > GPU\n",
        "print(\"Number of available GPUs:\", len(tf.config.list_physical_devices('GPU')))\n",
        "assert len(tf.config.list_physical_devices('GPU')) > 0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbquIatrMhl5"
      },
      "source": [
        "## 3.2 Importar datos\n",
        "\n",
        "![Let's Dance!](http://33.media.tumblr.com/3d223954ad0a77f4e98a7b87136aa395/tumblr_nlct5lFVbF1qhu7oio1_500.gif)\n",
        "\n",
        "\n",
        "Se utilizará un conjunto de datos de cientos de canciones populares irlandesas, representadas en la notación ABC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TdqHF9aMMg2O"
      },
      "outputs": [],
      "source": [
        "# Download the dataset\n",
        "songs = mdl.lab1.load_training_data()\n",
        "\n",
        "print(\"The datasets contains\", len(songs), \"songs\")\n",
        "# Print one of the songs to inspect it in greater detail!\n",
        "example_song = songs[42]\n",
        "print(\"\\nExample song: \\n\", example_song)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JL1vZTSoNMK8"
      },
      "source": [
        "Se convertirá una canción en notación ABC a un audio y se reproducira."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cont = 1\n",
        "for i in songs:\n",
        "    print(\"Song\", cont , \"Long:\", len(i))\n",
        "    cont+=1"
      ],
      "metadata": {
        "id": "tXs61kC8ivjM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "11toYzhEEKDz"
      },
      "outputs": [],
      "source": [
        "# Convert the ABC notation to audio file and listen to it\n",
        "mdl.lab1.play_song(example_song)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAoA-sdBNq-j"
      },
      "source": [
        "Una cosa importante en la que pensar es que esta notación de música no solo contiene información sobre las notas que se están reproduciendo, sino que además hay metainformación como el título, la clave y el tiempo de la canción. ¿Cómo afecta la cantidad de caracteres diferentes que están presentes en el archivo de texto a la complejidad del problema de aprendizaje? Esto será importante pronto, cuando generemos una representación numérica para los datos de texto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cwx2648SNmrP"
      },
      "outputs": [],
      "source": [
        "# Join our list of song strings into a single string containing all songs\n",
        "songs_joined = \"\\n\\n\".join(songs)\n",
        "print(songs_joined)\n",
        "\n",
        "# Find all unique characters in the joined string\n",
        "vocab = sorted(set(songs_joined))\n",
        "print(\"There are\", len(vocab), \"unique characters in the dataset\")\n",
        "print(\"Vocab:\", vocab)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85bIOWR7OEQ-"
      },
      "source": [
        "## 3.3 Procesar el conjunto de datos para la tarea de aprendizaje\n",
        "\n",
        "Demos un paso atrás y consideremos nuestra tarea de predicción. Estamos tratando de entrenar un modelo RNN para aprender patrones en la música en formato ABC y luego usar este modelo para generar una nueva pieza musical.\n",
        "\n",
        "Desglosando esto, lo que realmente le estamos preguntando al modelo es: **dado un carácter, o una secuencia de caracteres, ¿cuál es el próximo carácter más probable? Entrenaremos el modelo para realizar esta tarea.**\n",
        "\n",
        "Para lograr esto, ingresaremos una secuencia de caracteres en el modelo y lo entrenaremos para predecir la salida, es decir, el siguiente carácter en cada paso de tiempo. Las RNNs mantienen un estado interno que depende de los elementos vistos anteriormente, por lo que la información sobre todos los caracteres vistos hasta un momento dado se tendrá en cuenta para generar la predicción.\n",
        "\n",
        "\n",
        "#### *Vectorizando el texto*\n",
        "\n",
        "Antes de comenzar a entrenar nuestro modelo de RNN, necesitaremos crear una representación numérica de nuestro conjunto de datos basado en texto. Para hacer esto, generaremos dos tablas de búsqueda: una que asigna caracteres a números y una segunda que asigna números a caracteres. Recuerde que acabamos de identificar los caracteres únicos presentes en el texto.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SkfE04Nh9cs1"
      },
      "outputs": [],
      "source": [
        "### Define numerical representation of text ###\n",
        "\n",
        "# Create a mapping from character to unique index.\n",
        "# For example, to get the index of the character \"d\",\n",
        "#   we can evaluate `char2idx[\"d\"]`.\n",
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "\n",
        "print(\"Char to int\", char2idx)\n",
        "\n",
        "# Create a mapping from indices to characters. This is\n",
        "#   the inverse of char2idx and allows us to convert back\n",
        "#   from unique index to the character in our vocabulary.\n",
        "idx2char = np.array(vocab)\n",
        "print(\"Int to char:\", idx2char)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yX4SvhO91EO"
      },
      "source": [
        "Esto nos da una representación entera para cada carácter. Observe que los caracteres únicos (es decir, nuestro vocabulario) en el texto están mapeados como índices de 0 a len (vocab). Veamos esta representación numérica de nuestro conjunto de datos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "adAdWtwW96vq"
      },
      "outputs": [],
      "source": [
        "print('{')\n",
        "for char,_ in zip(char2idx, range(83)):\n",
        "    print('  {:4s}: {:3d},'.format(repr(char), char2idx[char]))\n",
        "print('  ...\\n}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lwuXu6hp-UmZ"
      },
      "outputs": [],
      "source": [
        "### Vectorize the songs string ###\n",
        "\n",
        "'''TODO: Write a function to convert the all songs string to a vectorized\n",
        "    (i.e., numeric) representation. Use the appropriate mapping\n",
        "    above to convert from vocab characters to the corresponding indices.\n",
        "\n",
        "  NOTE: the output of the `vectorize_string` function\n",
        "  should be a np.array with `N` elements, where `N` is\n",
        "  the number of characters in the input string\n",
        "'''\n",
        "\n",
        "def vectorize_string(string):\n",
        "    #print(string)\n",
        "    vectorized_output = np.array([char2idx[char] for char in string])\n",
        "    return vectorized_output\n",
        "\n",
        "# Call the function\n",
        "vectorized_songs = vectorize_string(songs_joined)\n",
        "print(\"Vectorized songs:\", vectorized_songs, len(vectorized_songs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqxpSuZ1w-ub"
      },
      "source": [
        "También podemos ver cómo se asigna la primera parte del texto a una representación entera:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l1VKcQHcymwb"
      },
      "outputs": [],
      "source": [
        "print ('{} ---- characters mapped to int ----> {}'.format(repr(songs_joined[:10]), vectorized_songs[:10]))\n",
        "# check that vectorized_songs is a numpy array\n",
        "assert isinstance(vectorized_songs, np.ndarray), \"returned result should be a numpy array\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgsVvVxnymwf"
      },
      "source": [
        "### Crea ejemplos para el entrnamiento\n",
        "\n",
        "Nuestro siguiente paso es dividir el texto en secuencias de ejemplo que usaremos durante el entrenamiento. Cada secuencia de entrada que alimentamos a nuestra RNN contendrá caracteres `seq_length` del texto. También necesitaremos definir una secuencia objetivo para cada secuencia de entrada, que se utilizará en el entrenamiento de la RNN para predecir el siguiente carácter. Para cada entrada, el destino correspondiente contendrá la misma longitud de texto, excepto que se desplazará un carácter hacia la derecha.\n",
        "\n",
        "Para hacer esto, dividiremos el texto en trozos de `seq_length + 1`. Suponga que `seq_length` es 4 y nuestro texto es\" Hola \". Entonces, nuestra secuencia de entrada es \"Hol\" y la secuencia objetivo es \"ola\".\n",
        "\n",
        "El método por lotes nos permitirá convertir este flujo de índices de caracteres en secuencias del tamaño deseado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LF-N8F7BoDRi"
      },
      "outputs": [],
      "source": [
        "### Batch definition to create training examples ###\n",
        "\n",
        "def get_batch(vectorized_songs, seq_length, batch_size):\n",
        "  # the length of the vectorized songs string\n",
        "  n = vectorized_songs.shape[0] - 1\n",
        "  #print(\"n:\", n)\n",
        "  # randomly choose the starting indices for the examples in the training batch\n",
        "\n",
        "  #print(\"Random choice:\",n-seq_length, batch_size)\n",
        "  idx = np.random.choice(n-seq_length, batch_size) # Two samples\n",
        "  #print(\"idx:\", idx)\n",
        "\n",
        "  '''TODO: construct a list of input sequences for the training batch'''\n",
        "  input_batch = [vectorized_songs[i : i+seq_length] for i in idx]\n",
        "  # input_batch = # TODO\n",
        "  #print(\"Input_batch:\", input_batch)\n",
        "  '''TODO: construct a list of output sequences for the training batch'''\n",
        "  output_batch = [vectorized_songs[i+1 : i+seq_length+1] for i in idx]\n",
        "  #print(\"Output_batch:\", output_batch)\n",
        "  #print()\n",
        "  # output_batch = # TODO\n",
        "\n",
        "  # x_batch, y_batch provide the true inputs and targets for network training\n",
        "  x_batch = np.reshape(input_batch, [batch_size, seq_length])\n",
        "  y_batch = np.reshape(output_batch, [batch_size, seq_length])\n",
        "  return x_batch, y_batch\n",
        "\n",
        "\n",
        "# Perform some simple tests to make sure your batch function is working properly!\n",
        "test_args = (vectorized_songs, 10, 2)\n",
        "\n",
        "if not mdl.lab1.test_batch_func_types(get_batch, test_args) or \\\n",
        "   not mdl.lab1.test_batch_func_shapes(get_batch, test_args) or \\\n",
        "   not mdl.lab1.test_batch_func_next_step(get_batch, test_args):\n",
        "   print(\"======\\n[FAIL] could not pass tests\")\n",
        "else:\n",
        "   print(\"======\\n[PASS] passed all tests!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_33OHL3b84i0"
      },
      "source": [
        "Para cada uno de estos vectores, cada índice se procesa en un solo paso de tiempo. Entonces, para la entrada en el paso de tiempo 0, el modelo recibe el índice del primer carácter de la secuencia e intenta predecir el índice del siguiente carácter. En el siguiente paso de tiempo, hace lo mismo, pero la RNN considera la información del paso anterior, es decir, su estado actualizado, además de la entrada actual.\n",
        "\n",
        "Podemos hacer esto al observar cómo funciona con los primeros caracteres de nuestro texto:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0eBu9WZG84i0"
      },
      "outputs": [],
      "source": [
        "x_batch, y_batch = get_batch(vectorized_songs, seq_length=5, batch_size=1)\n",
        "#print(\"x_batch:\", x_batch)\n",
        "#print(\"y_batch:\", y_batch)\n",
        "\n",
        "\n",
        "for i, (input_idx, target_idx) in enumerate(zip(np.squeeze(x_batch), np.squeeze(y_batch))):\n",
        "    print(\"Step {:3d}\".format(i))\n",
        "    print(\"  input: {} ({:s})\".format(input_idx, repr(idx2char[int(input_idx)])))\n",
        "    print(\"  expected output: {} ({:s})\".format(target_idx, repr(idx2char[int(target_idx)])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6oUuElIMgVx"
      },
      "source": [
        "## 3.4 El modelo de red neuronal recurrente (RNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8gPwEjRzf-Z"
      },
      "source": [
        "Ahora estamos listos para definir y entrenar un modelo RNN utilizando un conjunto de datos de música en formato ABC, y luego usar ese modelo entrenado para generar una nueva canción. Entrenaremos a nuestra RNN usando lotes de fragmentos de canciones de nuestro conjunto de datos, que generamos en la sección anterior.\n",
        "\n",
        "El modelo se basa en la arquitectura LSTM, donde usamos un vector de estados para mantener información sobre las relaciones temporales entre caracteres consecutivos. La salida final del LSTM se alimenta a una capa [`Dense`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense) completamente conectada donde utilizarémos una función softmax sobre cada carácter del vocabulario, y luego muestrear de esta distribución para predecir el próximo carácter.\n",
        "\n",
        "Como presentamos en la primera parte de esta unidad, usaremos la API de Keras, específicamente, [`tf.keras.Sequential`](https://www.tensorflow.org/api_docs/python/tf/keras/models/Sequential). Se utilizan tres capas para definir el modelo:\n",
        "\n",
        "* [`tf.keras.layers.Embedding`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding): esta es la capa de entrada, que consta de una tabla de búsqueda entrenable que asigna los números de cada carácter a un vector con dimensiones \"embedding_dim\".\n",
        "* [`tf.keras.layers.LSTM`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM): Nuestra red LSTM, con tamaño` units = rnn_units`.\n",
        "* [`tf.keras.layers.Dense`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense): La capa de salida, con salidas`vocab_size`.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/aamini/introtodeeplearning/2019/lab1/img/lstm_unrolled-01-01.png\" alt=\"Drawing\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlaOqndqBmJo"
      },
      "source": [
        "### Definir el modelo RNN\n",
        "\n",
        "Ahora, definiremos una función que usaremos para construir el modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8DsWzojvkbc7"
      },
      "outputs": [],
      "source": [
        "def LSTM(rnn_units):\n",
        "  return tf.keras.layers.LSTM(\n",
        "    rnn_units,\n",
        "    return_sequences=True,\n",
        "    recurrent_initializer='glorot_uniform',\n",
        "    recurrent_activation='sigmoid',\n",
        "    stateful=True,\n",
        "  )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbWU4dMJmMvq"
      },
      "source": [
        "¡El tiempo ha llegado! Complete los `TODOs` para definir el modelo RNN dentro de la función` build_model`, y luego llame a la función que acaba de definir para crear una instancia del modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MtCrdfzEI2N0"
      },
      "outputs": [],
      "source": [
        "### Defining the RNN Model ###\n",
        "\n",
        "'''TODO: Add LSTM and Dense layers to define the RNN model using the Sequential API.'''\n",
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "  model = tf.keras.Sequential([\n",
        "    # Layer 1: Embedding layer to transform indices into dense vectors\n",
        "    #   of a fixed embedding size\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim),\n",
        "\n",
        "    # Layer 2: LSTM with `rnn_units` number of units.\n",
        "    # TODO: Call the LSTM function defined above to add this layer.\n",
        "    LSTM(rnn_units),\n",
        "    # LSTM('''TODO'''),\n",
        "\n",
        "    # Layer 3: Dense (fully-connected) layer that transforms the LSTM output\n",
        "    #   into the vocabulary size.\n",
        "    # TODO: Add the Dense layer.\n",
        "    tf.keras.layers.Dense(vocab_size)\n",
        "    # '''TODO: DENSE LAYER HERE'''\n",
        "  ])\n",
        "\n",
        "  return model\n",
        "\n",
        "# Build a simple model with default hyperparameters. You will get the\n",
        "#   chance to change these later.\n",
        "model = build_model(len(vocab), embedding_dim=256, rnn_units=1024, batch_size=32)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ubPo0_9Prjb"
      },
      "source": [
        "### Prueba el modelo RNN\n",
        "\n",
        "Siempre es una buena idea ejecutar algunas comprobaciones simples en nuestro modelo para ver si se comporta como se esperaba.\n",
        "\n",
        "Primero, podemos usar la función `Model.summary` para imprimir un resumen del funcionamiento interno de nuestro modelo. Aquí podemos comprobar las capas en el modelo, la forma de la salida de cada una de las capas, el tamaño del lote, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RwG1DD6rDrRM"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xeDn5nZD0LX"
      },
      "source": [
        "También podemos comprobar rápidamente la dimensionalidad de nuestra salida, utilizando una longitud de secuencia de 100. Tenga en cuenta que el modelo se puede ejecutar en entradas de cualquier longitud."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C-_70kKAPrPU"
      },
      "outputs": [],
      "source": [
        "x, y = get_batch(vectorized_songs, seq_length=100, batch_size=32)\n",
        "pred = model(x)\n",
        "#print(\"Input shape:      \", x.shape, \" # (batch_size, sequence_length)\")\n",
        "#print(\"Prediction shape: \", pred.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mT1HvFVUGpoE"
      },
      "source": [
        "### Predicciones del modelo no entrenado\n",
        "\n",
        "Echemos un vistazo a lo que predice nuestro modelo no entrenado.\n",
        "\n",
        "Para obtener predicciones reales del modelo, tomamos muestras de la distribución de salida, que está definida por una función de activación \"softmax\" sobre nuestro vocabulario de caracteres. Esto nos dará índices de caracteres reales. Esto significa que estamos usando una [distribución categórica](https://en.wikipedia.org/wiki/Categorical_distribution) para muestrear la predicción de ejemplo. Esto da una predicción del siguiente carácter (específicamente su índice) en cada paso de tiempo.\n",
        "\n",
        "Tenga en cuenta que tomamos muestras de esta distribución de probabilidad, en lugar de simplemente tomar el `argmax`, lo que puede hacer que el modelo se cicle.\n",
        "\n",
        "Probemos este muestreo para el primer ejemplo del lote."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4V4MfFg0RQJg"
      },
      "outputs": [],
      "source": [
        "sampled_indices = tf.random.categorical(pred[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()\n",
        "sampled_indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfLtsP3mUhCG"
      },
      "source": [
        "Ahora podemos decodificarlos para ver el texto predicho por el modelo no entrenado:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xWcFwPwLSo05"
      },
      "outputs": [],
      "source": [
        "print(\"Input: \\n\", repr(\"\".join(idx2char[int(x[0,i])] for i in range(len(x[0])))))\n",
        "print()\n",
        "print(\"Next Char Predictions: \\n\", repr(\"\".join(idx2char[sampled_indices])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEHHcRasIDm9"
      },
      "source": [
        "Como puedes ver, el texto predicho por el modelo no entrenado no tiene sentido. ¿Cómo podemos hacerlo mejor? ¡Podemos entrenar la red!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJL0Q0YPY6Ee"
      },
      "source": [
        "## 3.5 Entrenamiento del modelo: operaciones de pérdida y entrenamiento\n",
        "\n",
        "¡Ahora es el momento de entrenar al modelo!\n",
        "\n",
        "En este punto, podemos pensar en nuestro próximo problema de predicción de caracteres como un problema de clasificación estándar. Dado el estado anterior de la RNN, así como la entrada en un intervalo de tiempo determinado, queremos predecir la clase del siguiente carácter, es decir, predecir realmente el próximo carácter.\n",
        "\n",
        "Para entrenar nuestro modelo en esta tarea de clasificación, podemos usar una forma de pérdida de \"entropía cruzada\" (pérdida de probabilidad logarítmica negativa). Específicamente, usaremos como función de pérdida: [`sparse_categorical_crossentropy`](https://www.tensorflow.org/api_docs/python/tf/keras/losses/sparse_categorical_crossentropy), ya que utiliza objetivos enteros para tareas de clasificación categórica. Querremos calcular la pérdida utilizando los verdaderos objetivos, las \"etiquetas\", y los objetivos predichos, los \"logis\".\n",
        "\n",
        "Primero calculemos la pérdida usando nuestras predicciones de ejemplo del modelo no entrenado:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4HrXTACTdzY-"
      },
      "outputs": [],
      "source": [
        "### Defining the loss function ###\n",
        "\n",
        "'''TODO: define the loss function to compute and return the loss between\n",
        "    the true labels and predictions (logits). Set the argument from_logits=True.'''\n",
        "def compute_loss(labels, logits):\n",
        "  loss = tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
        "  # loss = tf.keras.losses.sparse_categorical_crossentropy('''TODO''', '''TODO''', from_logits=True) # TODO\n",
        "  return loss\n",
        "\n",
        "'''TODO: compute the loss using the true next characters from the example batch\n",
        "    and the predictions from the untrained model several cells above'''\n",
        "example_batch_loss = compute_loss(y, pred)\n",
        "# example_batch_loss = compute_loss('''TODO''', '''TODO''') # TODO\n",
        "\n",
        "print(\"Prediction shape: \", pred.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Seh7e6eRqd7"
      },
      "source": [
        "Comencemos definiendo algunos **hiperparámetros** para entrenar el modelo. Para empezar, hemos proporcionado algunos valores razonables para algunos de los parámetros. ¡Depende de usted usar lo que hemos aprendido en clase para ayudar a optimizar la selección de parámetros aquí!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JQWUUhKotkAY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "### Hyperparameter setting and optimization ###\n",
        "\n",
        "# Optimization parameters:\n",
        "num_training_iterations = 500  # Increase this to train longer\n",
        "batch_size = 32  # Experiment between 1 and 64\n",
        "seq_length = 100  # Experiment between 50 and 500\n",
        "learning_rate = 3e-3  # Experiment between 1e-5 and 1e-1\n",
        "\n",
        "# Model parameters:\n",
        "vocab_size = len(vocab)\n",
        "embedding_dim = 256\n",
        "rnn_units = 1024  # Experiment between 1 and 2048\n",
        "\n",
        "# Checkpoint location:\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"my_ckpt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cu11p1MKYZd"
      },
      "source": [
        "Ahora, estamos listos para definir nuestra operación de entrenamiento - el optimizador y la duración del entrenamiento - y usar esta función para entrenar el modelo. Experimentaremos con la elección del optimizador y el número de iteraciones (epochs), y verás cómo estos cambios afectan la salida de la red. Algunos optimizadores a probar son [`Adam`](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam?version=stable) y [` Adagrad`](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adagrad?version=stable).\n",
        "\n",
        "Primero, crearemos una instancia de un nuevo modelo y un optimizador. Luego, usaremos el método [`tf.GradientTape`](https://www.tensorflow.org/api_docs/python/tf/GradientTape) para realizar las operaciones de `\"back propagation\"`.\n",
        "\n",
        "También generaremos una impresión del progreso del modelo a través del entrenamiento, que nos ayudará a visualizar fácilmente si estamos minimizando o no la pérdida."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F31vzJ_u66cb"
      },
      "outputs": [],
      "source": [
        "### Define optimizer and training operation ###\n",
        "\n",
        "'''TODO: instantiate a new model for training using the `build_model`\n",
        "  function and the hyperparameters created above.'''\n",
        "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size)\n",
        "# model = build_model('''TODO: arguments''')\n",
        "\n",
        "'''TODO: instantiate an optimizer with its learning rate.\n",
        "  Checkout the tensorflow website for a list of supported optimizers.\n",
        "  https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/\n",
        "  Try using the Adam optimizer to start.'''\n",
        "optimizer = tf.keras.optimizers.Adagrad(learning_rate)\n",
        "# optimizer = # TODO\n",
        "\n",
        "@tf.function\n",
        "def train_step(x, y):\n",
        "  # Use tf.GradientTape()\n",
        "  with tf.GradientTape() as tape:\n",
        "\n",
        "    '''TODO: feed the current input into the model and generate predictions'''\n",
        "    y_hat = model(x) # TODO\n",
        "    # y_hat = model('''TODO''')\n",
        "\n",
        "    '''TODO: compute the loss!'''\n",
        "    loss = compute_loss(y, y_hat) # TODO\n",
        "    # loss = compute_loss('''TODO''', '''TODO''')\n",
        "\n",
        "  # Now, compute the gradients\n",
        "  '''TODO: complete the function call for gradient computation.\n",
        "      Remember that we want the gradient of the loss with respect all\n",
        "      of the model parameters.\n",
        "      HINT: use `model.trainable_variables` to get a list of all model\n",
        "      parameters.'''\n",
        "  grads = tape.gradient(loss, model.trainable_variables) # TODO\n",
        "  # grads = tape.gradient('''TODO''', '''TODO''')\n",
        "\n",
        "  # Apply the gradients to the optimizer so it can update the model accordingly\n",
        "  optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "  return loss\n",
        "\n",
        "##################\n",
        "# Begin training!#\n",
        "##################\n",
        "\n",
        "history = []\n",
        "plotter = mdl.util.PeriodicPlotter(sec=0.5, xlabel='Iterations', ylabel='Loss')\n",
        "if hasattr(tqdm, '_instances'): tqdm._instances.clear() # clear if it exists\n",
        "\n",
        "for iter in tqdm(range(num_training_iterations)): #tqdm displays progress\n",
        "\n",
        "  # Grab a batch and propagate it through the network\n",
        "  x_batch, y_batch = get_batch(vectorized_songs, seq_length, batch_size)\n",
        "  loss = train_step(x_batch, y_batch)\n",
        "\n",
        "  # Update the progress bar\n",
        "  history.append(loss.numpy().mean())\n",
        "  plotter.plot(history)\n",
        "\n",
        "  # Update the model with the changed weights!\n",
        "  #if iter % 100 == 0:\n",
        "  #model.save_weights(checkpoint_prefix+str(\".weights.h5\"))\n",
        "\n",
        "# Save the trained model and the weights\n",
        "model.save_weights(checkpoint_prefix+\".weights.h5\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKkD5M6eoSiN"
      },
      "source": [
        "## 3.6 Generar música usando el modelo RNN\n",
        "\n",
        "¡Ahora, podemos usar nuestro modelo RNN entrenado para generar algo de música! Al generar música, tendremos que alimentar el modelo con algún tipo de datos iniciales para que comience (¡porque no puede predecir nada sin algo para comenzar!).\n",
        "\n",
        "Una vez que tenemos datos iniciales (semilla generada), podemos predecir iterativamente cada carácter sucesivo (recuerda, estamos usando la representación ABC para nuestra música) usando nuestra RNN entrenado. Específicamente, recuerda que nuestra RNN utiliza una función de activación \"softmax\" sobre posibles caracteres sucesivos. Para la inferencia, tomamos muestras iterativas de estas distribuciones y luego usamos nuestras muestras para codificar una canción generada en el formato ABC.\n",
        "\n",
        "Entonces, ¡todo lo que tenemos que hacer es escribirlo en un archivo y escuchar!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIPcXllKjkdr"
      },
      "source": [
        "### Restaurar el último punto de control\n",
        "\n",
        "Para mantener este paso de inferencia simple, usaremos un tamaño de lote de 1. Debido a cómo se pasa el estado RNN de un paso de tiempo a otro, el modelo solo podrá aceptar un tamaño de lote fijo una vez que esté construido.\n",
        "\n",
        "Para ejecutar el modelo con un `batch_size` diferente, necesitaremos reconstruir, volver a entrenar el modelo y restaurar los pesos desde el último punto de control, es decir, los pesos después del último punto de control durante el entrenamiento:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LycQ-ot_jjyu"
      },
      "outputs": [],
      "source": [
        "'''TODO: Rebuild the model using a batch_size=1'''\n",
        "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1) # TODO\n",
        "# model = build_model('''TODO''', '''TODO''', '''TODO''', batch_size=1)\n",
        "\n",
        "# Restore the model weights for the last checkpoint after training\n",
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "model.build(tf.TensorShape([1, None]))\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9b4V2C8N62l"
      },
      "source": [
        "Observe que hemos introducido un `batch_size` fijo de 1 para la inferencia."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjGz1tDkzf-u"
      },
      "source": [
        "### El procedimiento de predicción\n",
        "\n",
        "Ahora, estamos listos para escribir el código para generar texto en el formato de música ABC:\n",
        "\n",
        "* Inicializar una cadena de inicio \"semilla\" y el estado RNN, y establecer el número de caracteres que queremos generar.\n",
        "\n",
        "* Utilice la cadena de inicio y el estado RNN para obtener la distribución de probabilidad sobre el siguiente carácter predicho.\n",
        "\n",
        "* Muestra de distribución multinomial para calcular el índice del carácter predicho. Este carácter predicho se utiliza luego como la siguiente entrada al modelo.\n",
        "\n",
        "* En cada paso de tiempo, el estado de la RNN actualizado se retroalimenta en el modelo, de modo que ahora tiene más contexto para hacer la próxima predicción. Después de predecir el siguiente carácter, los estados RNN actualizados se retroalimentan nuevamente en el modelo, que es la forma en que aprende las dependencias de secuencia en los datos, a medida que obtiene más información de las predicciones anteriores.\n",
        "\n",
        "![Inferencia de LSTM](https://raw.githubusercontent.com/aamini/introtodeeplearning/2019/lab1/img/lstm_inference.png)\n",
        "\n",
        "Complete y experimente con este bloque de código (¡así como con algunos de los aspectos de la definición y el entrenamiento de la red!), Y vea cómo funciona el modelo. ¿Cómo se comparan las canciones generadas después del entrenamiento con un pequeño número de épocas con las generadas después de un entrenamiento de mayor duración?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WvuwZBX5Ogfd"
      },
      "outputs": [],
      "source": [
        "### Prediction of a generated song ###\n",
        "\n",
        "def generate_text(model, start_string, generation_length=1000):\n",
        "  # Evaluation step (generating ABC text using the learned RNN model)\n",
        "\n",
        "  '''TODO: convert the start string to numbers (vectorize)'''\n",
        "  input_eval = [char2idx[s] for s in start_string] # TODO\n",
        "  # input_eval = ['''TODO''']\n",
        "  input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "  # Empty string to store our results\n",
        "  text_generated = []\n",
        "\n",
        "  # Here batch size == 1\n",
        "  model.reset_states()\n",
        "  tqdm._instances.clear()\n",
        "\n",
        "  for i in tqdm(range(generation_length)):\n",
        "      '''TODO: evaluate the inputs and generate the next character predictions'''\n",
        "      predictions = model(input_eval)\n",
        "      # predictions = model('''TODO''')\n",
        "\n",
        "      # Remove the batch dimension\n",
        "      predictions = tf.squeeze(predictions, 0)\n",
        "\n",
        "      '''TODO: use a multinomial distribution to sample'''\n",
        "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "      # predicted_id = tf.random.categorical('''TODO''', num_samples=1)[-1,0].numpy()\n",
        "\n",
        "      # Pass the prediction along with the previous hidden state\n",
        "      #   as the next inputs to the model\n",
        "      input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "      '''TODO: add the predicted character to the generated text!'''\n",
        "      # Hint: consider what format the prediction is in vs. the output\n",
        "      text_generated.append(idx2char[predicted_id]) # TODO\n",
        "      # text_generated.append('''TODO''')\n",
        "\n",
        "  return (start_string + ''.join(text_generated))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ktovv0RFhrkn"
      },
      "outputs": [],
      "source": [
        "'''TODO: Use the model and the function defined above to generate ABC format text of length 1000!\n",
        "    As you may notice, ABC files start with \"X\" - this may be a good start string.'''\n",
        "generated_text = generate_text(model, start_string=\"X\", generation_length=3000) # TODO\n",
        "print(\"Gen text:\", generated_text)\n",
        "# generated_text = generate_text('''TODO''', start_string=\"X\", generation_length=1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AM2Uma_-yVIq"
      },
      "source": [
        "### ¡Reproduce la música generada!\n",
        "\n",
        "¡Ahora podemos llamar a una función para convertir el texto en formato ABC en un archivo de audio, y luego reproducirlo para ver nuestra música generada! Intente entrenar más tiempo si la canción resultante no es lo suficientemente larga, ¡o vuelva a generar la canción!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LrOtG64bfLto"
      },
      "outputs": [],
      "source": [
        "### Play back generated songs ###\n",
        "\n",
        "generated_songs = mdl.lab1.extract_song_snippet(generated_text)\n",
        "\n",
        "for i, song in enumerate(generated_songs):\n",
        "  # Synthesize the waveform from a song\n",
        "  waveform = mdl.lab1.play_song(song)\n",
        "\n",
        "  # If its a valid song (correct syntax), lets play it!\n",
        "  if waveform:\n",
        "    print(\"Generated song\", i)\n",
        "    ipythondisplay.display(waveform)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgVvcrYmSKGG"
      },
      "source": [
        "## 3.7 ¡Experimenta y produce tus propias canciones!\n",
        "\n",
        "¡Felicitaciones por hacer su primer modelo de secuencia en TensorFlow! Es un logro bastante grande, y espero que tengas algunas melodías dulces para mostrar.\n",
        "\n",
        "Considere cómo puede mejorar su modelo y qué parece ser más importante en términos de rendimiento. Aquí hay algunas ideas para comenzar:\n",
        "\n",
        "* ¿Cómo afecta el número de épocas de entrenamiento al rendimiento?\n",
        "* ¿Qué sucede si modifica o aumenta el conjunto de datos?\n",
        "* ¿La elección de la cadena de inicio afecta significativamente el resultado?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87LMsBcu-x07"
      },
      "source": [
        "## 3.8 Ejercicio\n",
        "\n",
        "+ Generar automáticamente otro tipo de musica.\n",
        "\n",
        "> Ejemplo: [Mathematical Mozart GitHub](https://github.com/sarthakagarwal18/Mathematical-Mozart)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ANu1t_1gjs7H"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import yfinance as yf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "\n",
        "# 1. Descargar datos de Google usando yfinance\n",
        "df = yf.download('GOOGL', start='2010-01-01', end='2022-01-01')\n",
        "df = df[['Close']]\n",
        "\n",
        "# 2. Preprocesar los datos\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled_data = scaler.fit_transform(df.values)\n",
        "\n",
        "train_size = int(len(df) * 0.8)\n",
        "train_data = scaled_data[:train_size]\n",
        "test_data = scaled_data[train_size:]\n",
        "\n",
        "# Crear datos de entrenamiento\n",
        "def create_dataset(data, time_step=60):\n",
        "    x, y = [], []\n",
        "    for i in range(len(data) - time_step):\n",
        "        x.append(data[i:i + time_step])\n",
        "        y.append(data[i + time_step])\n",
        "    return np.array(x), np.array(y)\n",
        "\n",
        "time_step = 60\n",
        "x_train, y_train = create_dataset(train_data, time_step)\n",
        "x_test, y_test = create_dataset(test_data, time_step)\n",
        "\n",
        "# Reshape para LSTM (samples, time_steps, features)\n",
        "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
        "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))\n",
        "\n",
        "# 3. Crear modelo LSTM\n",
        "model = Sequential()\n",
        "model.add(LSTM(units=50, return_sequences=True, input_shape=(x_train.shape[1], 1)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(units=50, return_sequences=False))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(units=25))\n",
        "model.add(Dense(units=1))\n",
        "\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# 4. Entrenar el modelo\n",
        "model.fit(x_train, y_train, batch_size=64, epochs=10)\n",
        "\n",
        "# 5. Hacer predicciones y evaluar el modelo\n",
        "predictions = model.predict(x_test)\n",
        "predictions = scaler.inverse_transform(predictions)\n",
        "\n",
        "# Visualización\n",
        "train = df[:train_size]\n",
        "valid = df[train_size:]\n",
        "valid['Predictions'] = predictions\n",
        "\n",
        "plt.figure(figsize=(16, 8))\n",
        "plt.title('Predicción de precios de acciones de Google')\n",
        "plt.plot(train['Close'], label='Datos de entrenamiento')\n",
        "plt.plot(valid['Close'], label='Real')\n",
        "plt.plot(valid['Predictions'], label='Predicciones')\n",
        "plt.legend(['Entrenamiento', 'Real', 'Predicciones'], loc='lower right')\n",
        "plt.show()\n"
      ]
    }
  ]
}